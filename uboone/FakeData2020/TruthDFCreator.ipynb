{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python tools loaded.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../../common/\")\n",
    "from python_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba.extending\n",
    "\n",
    "@numba.extending.overload(np.clip)\n",
    "def np_clip(a, a_min, a_max, out=None):\n",
    "    def np_clip_impl(a, a_min, a_max, out=None):\n",
    "        if out is None:\n",
    "            out = np.empty_like(a)\n",
    "        for i in range(len(a)):\n",
    "            if a[i] < a_min:\n",
    "                out[i] = a_min\n",
    "            elif a[i] > a_max:\n",
    "                out[i] = a_max\n",
    "            else:\n",
    "                out[i] = a[i]\n",
    "        return out\n",
    "    return np_clip_impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful functions\n",
    "# \n",
    "# you may need to comment out the 'numba' bits if your system can't install numba (like the gpvms...)\n",
    "#\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def costheta_numba(p1x,p1y,p1z,p1mag,\n",
    "                   p2x,p2y,p2z,p2mag):\n",
    "    return np.clip(np.where((p1mag>0.0)&(p2mag>0.0),\n",
    "                            (p1x*p2x+p1y*p2y+p1z*p2z)/p1mag/p2mag,\n",
    "                            np.nan),\n",
    "                   -1.0,1.0)\n",
    "\n",
    "def eval_costheta(df,suffix1=\"\",suffix2=\"\"):\n",
    "    return costheta_numba(df.loc[:,\"px\"+suffix1].values,df.loc[:,\"py\"+suffix1].values,df.loc[:,\"pz\"+suffix1].values,df.loc[:,\"p\"+suffix1].values,\n",
    "                          df.loc[:,\"px\"+suffix2].values,df.loc[:,\"py\"+suffix2].values,df.loc[:,\"pz\"+suffix2].values,df.loc[:,\"p\"+suffix2].values)\n",
    "\n",
    "    \n",
    "@numba.jit(nopython=True)\n",
    "def q3_numba(p1x,p1y,p1z,p2x,p2y,p2z):\n",
    "    return np.sqrt((p1x-p2x)**2+(p1y-p2y)**2+(p1z-p2z)**2)\n",
    "\n",
    "def eval_q3(df,suffix1=\"\",suffix2=\"_mu\"):\n",
    "    return q3_numba(df.loc[:,\"px\"+suffix1].values,df.loc[:,\"py\"+suffix1].values,df.loc[:,\"pz\"+suffix1].values,\n",
    "                    df.loc[:,\"px\"+suffix2].values,df.loc[:,\"py\"+suffix2].values,df.loc[:,\"pz\"+suffix2].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_files(sig_files,bkg_files,bkg_path,aa_run,aa_label,ac_run,ac_label):\n",
    "    for f in sig_files:\n",
    "        r = int(f.split(\"/\")[-1].split(\"_\")[-2])\n",
    "        sr = f.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "        run_set=\"\"\n",
    "        if(r==aa_run):\n",
    "            run_set=aa_label\n",
    "        if(r==ac_run):\n",
    "            run_set=ac_label\n",
    "    \n",
    "        fname = \"%s_%s/sampler_hist_%s.root\"%(bkg_path,run_set,sr)\n",
    "        try:\n",
    "            bkg_files.remove(fname)\n",
    "        except:\n",
    "            print(\"%s not found. (%s)\"%(fname,f))\n",
    "            sig_files.remove(f)\n",
    "    all_files = sig_files + bkg_files\n",
    "    return all_files,sig_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_root(root_filenames,id_tree=True):\n",
    "    t_df = []\n",
    "    p_df = []\n",
    "    pot_df = []\n",
    "    id_df = []\n",
    "\n",
    "    file_count = 0\n",
    "    event_count = 0\n",
    "    print(\"Processing %d files\" % len(root_filenames))\n",
    "\n",
    "    for root_filename in root_filenames:\n",
    "    \n",
    "        try:\n",
    "            p_df.append(uproot.open(root_filename)['mcana/particle_tree'].pandas.df())\n",
    "            t_df.append(uproot.open(root_filename)['mcana/mctruth_tree'].pandas.df())\n",
    "            pot_df.append(uproot.open(root_filename)['potana/pot_tree'].pandas.df())\n",
    "        except:\n",
    "            print(\"File %s, trees not found.\"%root_filename)\n",
    "        \n",
    "        if id_tree:\n",
    "            try:\n",
    "                id_df.append(uproot.open(root_filename)['generator/id_tree'].pandas.df())\n",
    "            except:\n",
    "                print(\"\\tFile %s, No ID Tree. Skipping....\"%root_filename)\n",
    "            \n",
    "        event_count += len(t_df[-1])\n",
    "        file_count += 1\n",
    "        if file_count%500==0:\n",
    "            print(\"\\tProcessed %d files. %d events processed.\" % (file_count,event_count))\n",
    "\n",
    "    p_df = pd.concat(p_df)\n",
    "    t_df = pd.concat(t_df)\n",
    "    pot_df = pd.concat(pot_df)\n",
    "    if id_tree:\n",
    "        id_df = pd.concat(id_df)\n",
    "\n",
    "    p_df.set_index([\"run\",\"subrun\",\"event\",\"truth_index\",\"p_index\"],inplace=True)\n",
    "    t_df.set_index([\"run\",\"subrun\",\"event\",\"truth_index\"],inplace=True)\n",
    "    pot_df.set_index([\"run\",\"subrun\"],inplace=True)\n",
    "        \n",
    "    print(\"Have dataframe objects. Total events is %d.\" % len(t_df))\n",
    "    \n",
    "    #make a ke column\n",
    "    p_df[\"ke\"] = p_df[\"e\"]-p_df[\"mass\"]\n",
    "    \n",
    "    return t_df,p_df,pot_df,id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finalstate_df(p_df):\n",
    "    df_n = pd.DataFrame()\n",
    "    \n",
    "    df_n[\"n_mu\"] = ((p_df[\"status\"]==1)&(p_df[\"pdgcode\"]==13)).replace(False,np.nan)\n",
    "    df_n[\"n_e\"] = ((p_df[\"status\"]==1)&(p_df[\"pdgcode\"]==11)).replace(False,np.nan)\n",
    "    df_n[\"n_p_40MeV\"] = ((p_df[\"status\"]==1)&(p_df[\"pdgcode\"]==2212)&((p_df[\"e\"]-p_df[\"mass\"])>0.03)).replace(False,np.nan)\n",
    "    df_n[\"n_pi0\"] = ((p_df[\"status\"]==1)&((p_df[\"pdgcode\"]==111))).replace(False,np.nan)\n",
    "    df_n[\"n_chpi\"] = ((p_df[\"status\"]==1)&((p_df[\"pdgcode\"]==211)^(p_df[\"pdgcode\"]==-211))).replace(False,np.nan)\n",
    "    df_n[\"n_gamma\"] = ((p_df[\"status\"]==1)&((p_df[\"pdgcode\"]==22))&(p_df[\"e\"]>0.02)).replace(False,np.nan)\n",
    "    df_n = df_n.groupby([\"run\",\"subrun\",\"event\",\"truth_index\"]).agg(\"sum\")\n",
    "    \n",
    "    return df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupings for final state protons (up to 4), pi0, gammas, and leptons. And initial neutrino.\n",
    "def group_particle_df(p_df):\n",
    "    p_df_p_grouped = p_df.query(\"status==1 and pdgcode==2212\").sort_values(by=[\"e\"],ascending=False).groupby([\"run\",\"subrun\",\"event\",\"truth_index\"])\n",
    "    p_df_p1 = p_df_p_grouped.nth(0)\n",
    "    p_df_p2 = p_df_p_grouped.nth(1)\n",
    "    p_df_p3 = p_df_p_grouped.nth(2)\n",
    "    p_df_p4 = p_df_p_grouped.nth(3)\n",
    "\n",
    "    p_df_pi0_grouped = p_df.query(\"status==1 and pdgcode==111\").sort_values(by=[\"e\"],ascending=False).groupby([\"run\",\"subrun\",\"event\",\"truth_index\"])\n",
    "    p_df_pi0 = p_df_pi0_grouped.nth(0)\n",
    "\n",
    "    p_df_gamma_grouped = p_df.query(\"status==1 and pdgcode==22\").sort_values(by=[\"e\"],ascending=False).groupby([\"run\",\"subrun\",\"event\",\"truth_index\"])\n",
    "    p_df_gamma = p_df_gamma_grouped.nth(0)\n",
    "\n",
    "    p_df_lep = p_df.query(\"status==1 and (pdgcode==13 or pdgcode==-13 or pdgcode==11 or pdgcode==-11 or pdgcode==12 or pdgcode==-12 or pdgcode==14 or pdgcode==-14)\").groupby([\"run\",\"subrun\",\"event\",\"truth_index\"]).first()\n",
    "    p_df_nu = p_df.query(\"status==0 and (pdgcode==12 or pdgcode==-12 or pdgcode==14 or pdgcode==-14)\").groupby([\"run\",\"subrun\",\"event\",\"truth_index\"]).first()\n",
    "    \n",
    "    return p_df_nu,p_df_lep,p_df_p1,p_df_p2,p_df_p3,p_df_p4,p_df_pi0,p_df_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_df_calcs(df_ev_t):\n",
    "    df_ev_t[\"costheta_lep\"] = eval_costheta(df=df_ev_t,suffix1=\"\",suffix2=\"_lep\")\n",
    "    df_ev_t[\"costheta_p1\"] = eval_costheta(df=df_ev_t,suffix1=\"\",suffix2=\"_p1\")\n",
    "    \n",
    "    return df_ev_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_event_df(t_df,p_df):\n",
    "    df_n = create_finalstate_df(p_df)\n",
    "    p_df_nu,p_df_lep,p_df_p1,p_df_p2,p_df_p3,p_df_p4,p_df_pi0,p_df_gamma = group_particle_df(p_df)\n",
    "    \n",
    "    df_ev_t = t_df.copy()\n",
    "    df_ev_t = df_ev_t.merge(p_df_nu,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_nu\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_lep,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_lep\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_p1,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_p1\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_p2,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_p2\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_p3,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_p3\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_p3,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_p4\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_pi0,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_pi0\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_gamma,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_gamma\"])\n",
    "    df_ev_t = df_ev_t.merge(df_n,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"])\n",
    "    \n",
    "    df_ev_t = event_df_calcs(df_ev_t)\n",
    "    \n",
    "    return df_ev_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_on_run_subrun(df,rs_df):\n",
    "    index_df = pd.MultiIndex.from_arrays([df.index.get_level_values('run').array,\n",
    "                                          df.index.get_level_values('subrun').array])\n",
    "    index_rs = pd.MultiIndex.from_arrays([rs_df[col] for col in ['run', 'subrun']])\n",
    "    return df.loc[index_df.isin(index_rs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hdf(name,t_df=None,p_df=None,pot_df=None,ev_df=None,id_df=None):\n",
    "    if t_df is not None: t_df.to_hdf(name,\"t_df\")\n",
    "    if p_df is not None: p_df.to_hdf(name,\"p_df\")\n",
    "    if pot_df is not None: pot_df.to_hdf(name,\"pot_df\")\n",
    "    if ev_df is not None: ev_df.to_hdf(name,\"ev_df\")\n",
    "    if id_df is not None: id_df.to_hdf(name,\"id_df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_filenames_Set1Run1_Sigs = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1_SignalFiles/*.root\")\n",
    "root_filenames_Set1Run1_Bkgs = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1_A[A,C]/*.root\")\n",
    "root_filenames_Set1Run3_Sigs = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run3_Sampler_Hists_Set1/Run3_SignalFiles/*.root\")\n",
    "root_filenames_Set1Run3_Bkgs = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run3_Sampler_Hists_Set1/Run3b_A[B,C]/*.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1_AC/sampler_hist_-1.root not found. (/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1_SignalFiles/sampler_hist_6693859_-1.root)\n"
     ]
    }
   ],
   "source": [
    "root_filenames_Set1Run1,root_filenames_Set1Run1_Sigs = remove_duplicate_files(root_filenames_Set1Run1_Sigs,\n",
    "                                                                              root_filenames_Set1Run1_Bkgs,\n",
    "                                                                              \"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1\",\n",
    "                                                                              6693842,\"AA\",6693859,\"AC\")\n",
    "root_filenames_Set1Run3,root_filenames_Set1Run3_Sigs = remove_duplicate_files(root_filenames_Set1Run3_Sigs,\n",
    "                                                                              root_filenames_Set1Run3_Bkgs,\n",
    "                                                                              \"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run3_Sampler_Hists_Set1/Run3b\",\n",
    "                                                                              7165574,\"AB\",7165592,\"AC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_filenames_CV   = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/CVSet/*/*/sampler*.root\")\n",
    "root_filenames_Set1 = root_filenames_Set1Run1+root_filenames_Set1Run3\n",
    "root_filenames_Set2 = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/*/*/sampler*.root\")\n",
    "root_filenames_Set3 = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set3/*/*/sampler*.root\")\n",
    "root_filenames_Set4 = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set4/*/*/sampler*.root\")\n",
    "root_filenames_Set5 = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set5/*/truth_Output.root\")\n",
    "root_filenames_Set7 = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/*/*/sampler*.root\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_reco2_set1_files = [\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Set1_Run1_RSub.txt\",\n",
    "                 \"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Set1_Run3_RSub.txt\"]\n",
    "rs_df_reco2 = pd.concat([pd.read_csv(f,names=[\"run\",\"subrun\"],header=None,sep=\".\") for f in rs_reco2_set1_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df,p_df,pot_df,id_df = convert_root(root_filenames_CV)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/CVSet/mcana_dfs_Aug18.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df,p_df,pot_df,id_df = convert_root(root_filenames_Set1)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "ev_df = merge_on_run_subrun(ev_df,rs_df_reco2)\n",
    "t_df = merge_on_run_subrun(t_df,rs_df_reco2)\n",
    "pot_df = merge_on_run_subrun(pot_df,rs_df_reco2)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/mcana_dfs_Aug19.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_df,p_df,pot_df,id_df = convert_root(root_filenames_Set2)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/mcana_dfs_Sep03.h5\",\n",
    "          t_df,p_df,pot_df,ev_df,id_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_df,p_df,pot_df,id_df = convert_root(root_filenames_Set3)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set3/mcana_dfs_Sep03.h5\",\n",
    "          t_df,p_df,pot_df,ev_df,id_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_df,p_df,pot_df,id_df = convert_root(root_filenames_Set4)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set4/mcana_dfs_Aug18.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df,p_df,pot_df,id_df = convert_root(root_filenames_Set5)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set5/mcana_dfs.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set5/mcana_dfs.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 23542 files\n",
      "\tProcessed 500 files. 7601 events processed.\n",
      "\tProcessed 1000 files. 15783 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run1/38017786_7551/sampler_hist_7551.root, trees not found.\n",
      "\tFile /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run1/38017786_7551/sampler_hist_7551.root, No ID Tree. Skipping....\n",
      "\tProcessed 1500 files. 23188 events processed.\n",
      "\tProcessed 2000 files. 30529 events processed.\n",
      "\tProcessed 2500 files. 37948 events processed.\n",
      "\tProcessed 3000 files. 45521 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run1/38017786_4639/sampler_hist_4639.root, trees not found.\n",
      "\tFile /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run1/38017786_4639/sampler_hist_4639.root, No ID Tree. Skipping....\n",
      "\tProcessed 3500 files. 52757 events processed.\n",
      "\tProcessed 4000 files. 59863 events processed.\n",
      "\tProcessed 4500 files. 67026 events processed.\n",
      "\tProcessed 5000 files. 74458 events processed.\n",
      "\tProcessed 5500 files. 81927 events processed.\n",
      "\tProcessed 6000 files. 89056 events processed.\n",
      "\tProcessed 6500 files. 96230 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run1/38017786_9242/sampler_hist_9242.root, trees not found.\n",
      "\tFile /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run1/38017786_9242/sampler_hist_9242.root, No ID Tree. Skipping....\n",
      "\tProcessed 7000 files. 103588 events processed.\n",
      "\tProcessed 7500 files. 110940 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run1/38017786_6410/sampler_hist_6410.root, trees not found.\n",
      "\tFile /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run1/38017786_6410/sampler_hist_6410.root, No ID Tree. Skipping....\n",
      "\tProcessed 8000 files. 118421 events processed.\n",
      "\tProcessed 8500 files. 125708 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run1/38017786_3623/sampler_hist_3623.root, trees not found.\n",
      "\tFile /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run1/38017786_3623/sampler_hist_3623.root, No ID Tree. Skipping....\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run1/38017786_5527/sampler_hist_5527.root, trees not found.\n",
      "\tFile /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run1/38017786_5527/sampler_hist_5527.root, No ID Tree. Skipping....\n",
      "\tProcessed 9000 files. 132967 events processed.\n",
      "\tProcessed 9500 files. 140476 events processed.\n",
      "\tProcessed 10000 files. 147675 events processed.\n",
      "\tProcessed 10500 files. 154997 events processed.\n",
      "\tProcessed 11000 files. 162295 events processed.\n",
      "\tProcessed 11500 files. 169582 events processed.\n",
      "\tProcessed 12000 files. 177033 events processed.\n",
      "\tProcessed 12500 files. 184144 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run3b/37280747_6955/sampler_hist_6955.root, trees not found.\n",
      "\tFile /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run3b/37280747_6955/sampler_hist_6955.root, No ID Tree. Skipping....\n",
      "\tProcessed 13000 files. 191919 events processed.\n",
      "\tProcessed 13500 files. 200044 events processed.\n",
      "\tProcessed 14000 files. 207866 events processed.\n",
      "\tProcessed 14500 files. 216075 events processed.\n",
      "\tProcessed 15000 files. 224082 events processed.\n",
      "\tProcessed 15500 files. 232207 events processed.\n",
      "\tProcessed 16000 files. 240548 events processed.\n",
      "\tProcessed 16500 files. 248682 events processed.\n",
      "\tProcessed 17000 files. 256542 events processed.\n",
      "\tProcessed 17500 files. 264873 events processed.\n",
      "\tProcessed 18000 files. 272667 events processed.\n",
      "\tProcessed 18500 files. 280850 events processed.\n",
      "\tProcessed 19000 files. 288923 events processed.\n",
      "\tProcessed 19500 files. 296913 events processed.\n",
      "\tProcessed 20000 files. 305228 events processed.\n",
      "\tProcessed 20500 files. 313522 events processed.\n",
      "\tProcessed 21000 files. 321718 events processed.\n",
      "\tProcessed 21500 files. 329878 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run3b/37280747_5041/sampler_hist_5041.root, trees not found.\n",
      "\tFile /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run3b/37280747_5041/sampler_hist_5041.root, No ID Tree. Skipping....\n",
      "\tProcessed 22000 files. 338049 events processed.\n",
      "\tProcessed 22500 files. 346444 events processed.\n",
      "\tProcessed 23000 files. 354357 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run3b/37280747_2745/sampler_hist_2745.root, trees not found.\n",
      "\tFile /Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/Run3b/37280747_2745/sampler_hist_2745.root, No ID Tree. Skipping....\n",
      "\tProcessed 23500 files. 362281 events processed.\n",
      "Have dataframe objects. Total events is 362890.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.8/site-packages/numba/core/dispatcher.py:238: UserWarning: Numba extension module 'numba_scipy' failed to load due to 'ValueError(No function '__pyx_fuse_0pdtr' found in __pyx_capi__ of 'scipy.special.cython_special')'.\n",
      "  entrypoints.init_all()\n",
      "/Library/Python/3.8/site-packages/pandas/core/generic.py:2434: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->bytes,key->block2_values] [items->Index(['process', 'endprocess'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n",
      "/Library/Python/3.8/site-packages/pandas/core/generic.py:2434: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['process', 'endprocess', 'process_lep', 'endprocess_lep', 'process_p1',\n",
      "       'endprocess_p1', 'process_p2', 'endprocess_p2', 'process_p3',\n",
      "       'endprocess_p3', 'process_p4', 'endprocess_p4', 'process_pi0',\n",
      "       'endprocess_pi0', 'process_gamma', 'endprocess_gamma'],\n",
      "      dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    }
   ],
   "source": [
    "t_df,p_df,pot_df,id_df = convert_root(root_filenames_Set7)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set7/mcana_dfs.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_df = pot_df.sort_index()\n",
    "pot_df.loc[:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38051898, 38017787, 38017786, 37280747, 37280795], dtype=uint32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_df[\"run_new\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
