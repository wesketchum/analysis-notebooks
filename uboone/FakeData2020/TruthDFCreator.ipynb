{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python tools loaded.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../../common/\")\n",
    "from python_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba.extending\n",
    "\n",
    "@numba.extending.overload(np.clip)\n",
    "def np_clip(a, a_min, a_max, out=None):\n",
    "    def np_clip_impl(a, a_min, a_max, out=None):\n",
    "        if out is None:\n",
    "            out = np.empty_like(a)\n",
    "        for i in range(len(a)):\n",
    "            if a[i] < a_min:\n",
    "                out[i] = a_min\n",
    "            elif a[i] > a_max:\n",
    "                out[i] = a_max\n",
    "            else:\n",
    "                out[i] = a[i]\n",
    "        return out\n",
    "    return np_clip_impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful functions\n",
    "# \n",
    "# you may need to comment out the 'numba' bits if your system can't install numba (like the gpvms...)\n",
    "#\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def costheta_numba(p1x,p1y,p1z,p1mag,\n",
    "                   p2x,p2y,p2z,p2mag):\n",
    "    return np.clip(np.where((p1mag>0.0)&(p2mag>0.0),\n",
    "                            (p1x*p2x+p1y*p2y+p1z*p2z)/p1mag/p2mag,\n",
    "                            np.nan),\n",
    "                   -1.0,1.0)\n",
    "\n",
    "def eval_costheta(df,suffix1=\"\",suffix2=\"\"):\n",
    "    return costheta_numba(df.loc[:,\"px\"+suffix1].values,df.loc[:,\"py\"+suffix1].values,df.loc[:,\"pz\"+suffix1].values,df.loc[:,\"p\"+suffix1].values,\n",
    "                          df.loc[:,\"px\"+suffix2].values,df.loc[:,\"py\"+suffix2].values,df.loc[:,\"pz\"+suffix2].values,df.loc[:,\"p\"+suffix2].values)\n",
    "\n",
    "    \n",
    "@numba.jit(nopython=True)\n",
    "def q3_numba(p1x,p1y,p1z,p2x,p2y,p2z):\n",
    "    return np.sqrt((p1x-p2x)**2+(p1y-p2y)**2+(p1z-p2z)**2)\n",
    "\n",
    "def eval_q3(df,suffix1=\"\",suffix2=\"_mu\"):\n",
    "    return q3_numba(df.loc[:,\"px\"+suffix1].values,df.loc[:,\"py\"+suffix1].values,df.loc[:,\"pz\"+suffix1].values,\n",
    "                    df.loc[:,\"px\"+suffix2].values,df.loc[:,\"py\"+suffix2].values,df.loc[:,\"pz\"+suffix2].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_files(sig_files,bkg_files,bkg_path,aa_run,aa_label,ac_run,ac_label):\n",
    "    for f in sig_files:\n",
    "        r = int(f.split(\"/\")[-1].split(\"_\")[-2])\n",
    "        sr = f.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "        run_set=\"\"\n",
    "        if(r==aa_run):\n",
    "            run_set=aa_label\n",
    "        if(r==ac_run):\n",
    "            run_set=ac_label\n",
    "    \n",
    "        fname = \"%s_%s/sampler_hist_%s.root\"%(bkg_path,run_set,sr)\n",
    "        try:\n",
    "            bkg_files.remove(fname)\n",
    "        except:\n",
    "            print(\"%s not found. (%s)\"%(fname,f))\n",
    "            sig_files.remove(f)\n",
    "    all_files = sig_files + bkg_files\n",
    "    return all_files,sig_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_filenames_Set1Run1_Sigs = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1_SignalFiles/*.root\")\n",
    "root_filenames_Set1Run1_Bkgs = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1_A[A,C]/*.root\")\n",
    "root_filenames_Set1Run3_Sigs = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run3_Sampler_Hists_Set1/Run3_SignalFiles/*.root\")\n",
    "root_filenames_Set1Run3_Bkgs = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run3_Sampler_Hists_Set1/Run3b_A[B,C]/*.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1_AC/sampler_hist_-1.root not found. (/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1_SignalFiles/sampler_hist_6693859_-1.root)\n"
     ]
    }
   ],
   "source": [
    "root_filenames_Set1Run1,root_filenames_Set1Run1_Sigs = remove_duplicate_files(root_filenames_Set1Run1_Sigs,\n",
    "                                                                              root_filenames_Set1Run1_Bkgs,\n",
    "                                                                              \"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1\",\n",
    "                                                                              6693842,\"AA\",6693859,\"AC\")\n",
    "root_filenames_Set1Run3,root_filenames_Set1Run3_Sigs = remove_duplicate_files(root_filenames_Set1Run3_Sigs,\n",
    "                                                                              root_filenames_Set1Run3_Bkgs,\n",
    "                                                                              \"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run3_Sampler_Hists_Set1/Run3b\",\n",
    "                                                                              7165574,\"AB\",7165592,\"AC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_filenames_CV   = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/CVSet/*/*/sampler*.root\")\n",
    "root_filenames_Set1 = root_filenames_Set1Run1+root_filenames_Set1Run3\n",
    "root_filenames_Set2 = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/*/*/sampler*.root\")\n",
    "root_filenames_Set3 = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set3/*/*/sampler*.root\")\n",
    "root_filenames_Set4 = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set4/*/*/sampler*.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28537 15423 13114\n"
     ]
    }
   ],
   "source": [
    "print(len(root_filenames_Set1),len(root_filenames_Set1Run1),len(root_filenames_Set1Run3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_root(root_filenames):\n",
    "    t_df = []\n",
    "    p_df = []\n",
    "    pot_df = []\n",
    "    id_df = []\n",
    "\n",
    "    file_count = 0\n",
    "    event_count = 0\n",
    "    print(\"Processing %d files\" % len(root_filenames))\n",
    "\n",
    "    for root_filename in root_filenames:\n",
    "    \n",
    "        try:\n",
    "            p_df.append(uproot.open(root_filename)['mcana/particle_tree'].pandas.df())\n",
    "            t_df.append(uproot.open(root_filename)['mcana/mctruth_tree'].pandas.df())\n",
    "            pot_df.append(uproot.open(root_filename)['potana/pot_tree'].pandas.df())\n",
    "        except:\n",
    "            print(\"File %s, trees not found.\"%root_filename)\n",
    "        \n",
    "        try:\n",
    "            id_df.append(uproot.open(root_filename)['generator/id_tree'].pandas.df())\n",
    "        except:\n",
    "            print(\"\\tFile %s, No ID Tree. Skipping....\")\n",
    "            \n",
    "        event_count += len(t_df[-1])\n",
    "        file_count += 1\n",
    "        if file_count%500==0:\n",
    "            print(\"\\tProcessed %d files. %d events processed.\" % (file_count,event_count))\n",
    "\n",
    "    p_df = pd.concat(p_df)\n",
    "    t_df = pd.concat(t_df)\n",
    "    pot_df = pd.concat(pot_df)\n",
    "    id_df = pd.concat(id_df)\n",
    "\n",
    "    p_df.set_index([\"run\",\"subrun\",\"event\",\"truth_index\",\"p_index\"],inplace=True)\n",
    "    t_df.set_index([\"run\",\"subrun\",\"event\",\"truth_index\"],inplace=True)\n",
    "    pot_df.set_index([\"run\",\"subrun\"],inplace=True)\n",
    "        \n",
    "    print(\"Have dataframe objects. Total events is %d.\" % len(t_df))\n",
    "    \n",
    "    #make a ke column\n",
    "    p_df[\"ke\"] = p_df[\"e\"]-p_df[\"mass\"]\n",
    "    \n",
    "    return t_df,p_df,pot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finalstate_df(p_df):\n",
    "    df_n = pd.DataFrame()\n",
    "    \n",
    "    df_n[\"n_mu\"] = ((p_df[\"status\"]==1)&(p_df[\"pdgcode\"]==13)).replace(False,np.nan)\n",
    "    df_n[\"n_e\"] = ((p_df[\"status\"]==1)&(p_df[\"pdgcode\"]==11)).replace(False,np.nan)\n",
    "    df_n[\"n_p_40MeV\"] = ((p_df[\"status\"]==1)&(p_df[\"pdgcode\"]==2212)&((p_df[\"e\"]-p_df[\"mass\"])>0.03)).replace(False,np.nan)\n",
    "    df_n[\"n_pi0\"] = ((p_df[\"status\"]==1)&((p_df[\"pdgcode\"]==111))).replace(False,np.nan)\n",
    "    df_n[\"n_chpi\"] = ((p_df[\"status\"]==1)&((p_df[\"pdgcode\"]==211)^(p_df[\"pdgcode\"]==-211))).replace(False,np.nan)\n",
    "    df_n[\"n_gamma\"] = ((p_df[\"status\"]==1)&((p_df[\"pdgcode\"]==22))&(p_df[\"e\"]>0.02)).replace(False,np.nan)\n",
    "    df_n = df_n.groupby([\"run\",\"subrun\",\"event\",\"truth_index\"]).agg(\"sum\")\n",
    "    \n",
    "    return df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupings for final state protons (up to 4), pi0, gammas, and leptons. And initial neutrino.\n",
    "def group_particle_df(p_df):\n",
    "    p_df_p_grouped = p_df.query(\"status==1 and pdgcode==2212\").sort_values(by=[\"e\"],ascending=False).groupby([\"run\",\"subrun\",\"event\",\"truth_index\"])\n",
    "    p_df_p1 = p_df_p_grouped.nth(0)\n",
    "    p_df_p2 = p_df_p_grouped.nth(1)\n",
    "    p_df_p3 = p_df_p_grouped.nth(2)\n",
    "    p_df_p4 = p_df_p_grouped.nth(3)\n",
    "\n",
    "    p_df_pi0_grouped = p_df.query(\"status==1 and pdgcode==111\").sort_values(by=[\"e\"],ascending=False).groupby([\"run\",\"subrun\",\"event\",\"truth_index\"])\n",
    "    p_df_pi0 = p_df_pi0_grouped.nth(0)\n",
    "\n",
    "    p_df_gamma_grouped = p_df.query(\"status==1 and pdgcode==22\").sort_values(by=[\"e\"],ascending=False).groupby([\"run\",\"subrun\",\"event\",\"truth_index\"])\n",
    "    p_df_gamma = p_df_gamma_grouped.nth(0)\n",
    "\n",
    "    p_df_lep = p_df.query(\"status==1 and (pdgcode==13 or pdgcode==-13 or pdgcode==11 or pdgcode==-11 or pdgcode==12 or pdgcode==-12 or pdgcode==14 or pdgcode==-14)\").groupby([\"run\",\"subrun\",\"event\",\"truth_index\"]).first()\n",
    "    p_df_nu = p_df.query(\"status==0 and (pdgcode==12 or pdgcode==-12 or pdgcode==14 or pdgcode==-14)\").groupby([\"run\",\"subrun\",\"event\",\"truth_index\"]).first()\n",
    "    \n",
    "    return p_df_nu,p_df_lep,p_df_p1,p_df_p2,p_df_p3,p_df_p4,p_df_pi0,p_df_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_df_calcs(df_ev_t):\n",
    "    df_ev_t[\"costheta_lep\"] = eval_costheta(df=df_ev_t,suffix1=\"\",suffix2=\"_lep\")\n",
    "    df_ev_t[\"costheta_p1\"] = eval_costheta(df=df_ev_t,suffix1=\"\",suffix2=\"_p1\")\n",
    "    \n",
    "    return df_ev_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_event_df(t_df,p_df):\n",
    "    df_n = create_finalstate_df(p_df)\n",
    "    p_df_nu,p_df_lep,p_df_p1,p_df_p2,p_df_p3,p_df_p4,p_df_pi0,p_df_gamma = group_particle_df(p_df)\n",
    "    \n",
    "    df_ev_t = t_df.copy()\n",
    "    df_ev_t = df_ev_t.merge(p_df_nu,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_nu\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_lep,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_lep\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_p1,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_p1\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_p2,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_p2\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_p3,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_p3\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_p3,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_p4\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_pi0,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_pi0\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_gamma,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_gamma\"])\n",
    "    df_ev_t = df_ev_t.merge(df_n,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"])\n",
    "    \n",
    "    df_ev_t = event_df_calcs(df_ev_t)\n",
    "    \n",
    "    return df_ev_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_on_run_subrun(df,rs_df):\n",
    "    index_df = pd.MultiIndex.from_arrays([df.index.get_level_values('run').array,\n",
    "                                          df.index.get_level_values('subrun').array])\n",
    "    index_rs = pd.MultiIndex.from_arrays([rs_df[col] for col in ['run', 'subrun']])\n",
    "    return df.loc[index_df.isin(index_rs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_reco2_set1_files = [\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Set1_Run1_RSub.txt\",\n",
    "                 \"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Set1_Run3_RSub.txt\"]\n",
    "rs_df_reco2 = pd.concat([pd.read_csv(f,names=[\"run\",\"subrun\"],header=None,sep=\".\") for f in rs_reco2_set1_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hdf(name,t_df,p_df,pot_df,df_ev_t):\n",
    "    t_df.to_hdf(name,\"t_df\")\n",
    "    p_df.to_hdf(name,\"p_df\")\n",
    "    pot_df.to_hdf(name,\"pot_df\")\n",
    "    df_ev_t.to_hdf(name,\"ev_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df,p_df,pot_df = convert_root(root_filenames_CV)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/CVSet/mcana_dfs_Aug18.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 28537 files\n",
      "\tProcessed 500 files. 8291 events processed.\n",
      "\tProcessed 1000 files. 13640 events processed.\n",
      "\tProcessed 1500 files. 19017 events processed.\n",
      "\tProcessed 2000 files. 24375 events processed.\n",
      "\tProcessed 2500 files. 29770 events processed.\n",
      "\tProcessed 3000 files. 35127 events processed.\n",
      "\tProcessed 3500 files. 40520 events processed.\n",
      "\tProcessed 4000 files. 45720 events processed.\n",
      "\tProcessed 4500 files. 51118 events processed.\n",
      "\tProcessed 5000 files. 56442 events processed.\n",
      "\tProcessed 5500 files. 61894 events processed.\n",
      "\tProcessed 6000 files. 67304 events processed.\n",
      "\tProcessed 6500 files. 72531 events processed.\n",
      "\tProcessed 7000 files. 77882 events processed.\n",
      "\tProcessed 7500 files. 83228 events processed.\n",
      "\tProcessed 8000 files. 88671 events processed.\n",
      "\tProcessed 8500 files. 94279 events processed.\n",
      "\tProcessed 9000 files. 99562 events processed.\n",
      "\tProcessed 9500 files. 104917 events processed.\n",
      "\tProcessed 10000 files. 110309 events processed.\n",
      "\tProcessed 10500 files. 119544 events processed.\n",
      "\tProcessed 11000 files. 129225 events processed.\n",
      "\tProcessed 11500 files. 138901 events processed.\n",
      "\tProcessed 12000 files. 148559 events processed.\n",
      "\tProcessed 12500 files. 158242 events processed.\n",
      "\tProcessed 13000 files. 167913 events processed.\n",
      "\tProcessed 13500 files. 177554 events processed.\n",
      "\tProcessed 14000 files. 187238 events processed.\n",
      "\tProcessed 14500 files. 196910 events processed.\n",
      "\tProcessed 15000 files. 206603 events processed.\n",
      "\tProcessed 15500 files. 216421 events processed.\n",
      "\tProcessed 16000 files. 226007 events processed.\n",
      "\tProcessed 16500 files. 235255 events processed.\n",
      "\tProcessed 17000 files. 244663 events processed.\n",
      "\tProcessed 17500 files. 253765 events processed.\n",
      "\tProcessed 18000 files. 263484 events processed.\n",
      "\tProcessed 18500 files. 272842 events processed.\n",
      "\tProcessed 19000 files. 282296 events processed.\n",
      "\tProcessed 19500 files. 291960 events processed.\n",
      "\tProcessed 20000 files. 301533 events processed.\n",
      "\tProcessed 20500 files. 311265 events processed.\n",
      "\tProcessed 21000 files. 320690 events processed.\n",
      "\tProcessed 21500 files. 330653 events processed.\n",
      "\tProcessed 22000 files. 340385 events processed.\n",
      "\tProcessed 22500 files. 350027 events processed.\n",
      "\tProcessed 23000 files. 359690 events processed.\n",
      "\tProcessed 23500 files. 369362 events processed.\n",
      "\tProcessed 24000 files. 378806 events processed.\n",
      "\tProcessed 24500 files. 388520 events processed.\n",
      "\tProcessed 25000 files. 398172 events processed.\n",
      "\tProcessed 25500 files. 407755 events processed.\n",
      "\tProcessed 26000 files. 417398 events processed.\n",
      "\tProcessed 26500 files. 427051 events processed.\n",
      "\tProcessed 27000 files. 436663 events processed.\n",
      "\tProcessed 27500 files. 446401 events processed.\n",
      "\tProcessed 28000 files. 455849 events processed.\n",
      "\tProcessed 28500 files. 465460 events processed.\n",
      "Have dataframe objects. Total events is 466225.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/3.7/site-packages/pandas/core/generic.py:2505: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->bytes,key->block2_values] [items->Index(['process', 'endprocess'], dtype='object')]\n",
      "\n",
      "  encoding=encoding,\n",
      "/Library/Python/3.7/site-packages/pandas/core/generic.py:2505: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->Index(['process', 'endprocess', 'process_lep', 'endprocess_lep', 'process_p1',\n",
      "       'endprocess_p1', 'process_p2', 'endprocess_p2', 'process_p3',\n",
      "       'endprocess_p3', 'process_p4', 'endprocess_p4', 'process_pi0',\n",
      "       'endprocess_pi0', 'process_gamma', 'endprocess_gamma'],\n",
      "      dtype='object')]\n",
      "\n",
      "  encoding=encoding,\n"
     ]
    }
   ],
   "source": [
    "t_df,p_df,pot_df = convert_root(root_filenames_Set1)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "ev_df = merge_on_run_subrun(ev_df,rs_df_reco2)\n",
    "t_df = merge_on_run_subrun(t_df,rs_df_reco2)\n",
    "pot_df = merge_on_run_subrun(pot_df,rs_df_reco2)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/mcana_dfs_Aug19.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_df,p_df,pot_df = convert_root(root_filenames_Set2)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/mcana_dfs_Aug18.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_df,p_df,pot_df = convert_root(root_filenames_Set3)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set3/mcana_dfs_Aug18.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_df,p_df,pot_df = convert_root(root_filenames_Set4)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set4/mcana_dfs_Aug18.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>totpot</th>\n",
       "      <th>totgoodpot</th>\n",
       "      <th>totspills</th>\n",
       "      <th>goodspills</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <th>subrun</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">6693842</th>\n",
       "      <th>6018</th>\n",
       "      <td>2.259947e+16</td>\n",
       "      <td>2.259947e+16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>2.185295e+16</td>\n",
       "      <td>2.185295e+16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9210</th>\n",
       "      <td>2.039070e+16</td>\n",
       "      <td>2.039070e+16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4969</th>\n",
       "      <td>1.777037e+16</td>\n",
       "      <td>1.777037e+16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6693859</th>\n",
       "      <th>2554</th>\n",
       "      <td>2.322413e+16</td>\n",
       "      <td>2.322413e+16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">7165574</th>\n",
       "      <th>3881</th>\n",
       "      <td>6.524193e+15</td>\n",
       "      <td>6.524193e+15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8666</th>\n",
       "      <td>1.464675e+16</td>\n",
       "      <td>1.464675e+16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>3.089360e+16</td>\n",
       "      <td>3.089360e+16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>2.037520e+16</td>\n",
       "      <td>2.037520e+16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7591</th>\n",
       "      <td>3.474616e+16</td>\n",
       "      <td>3.474616e+16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25864 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      totpot    totgoodpot  totspills  goodspills\n",
       "run     subrun                                                   \n",
       "6693842 6018    2.259947e+16  2.259947e+16          0           0\n",
       "        1640    2.185295e+16  2.185295e+16          0           0\n",
       "        9210    2.039070e+16  2.039070e+16          0           0\n",
       "        4969    1.777037e+16  1.777037e+16          0           0\n",
       "6693859 2554    2.322413e+16  2.322413e+16          0           0\n",
       "...                      ...           ...        ...         ...\n",
       "7165574 3881    6.524193e+15  6.524193e+15          0           0\n",
       "        8666    1.464675e+16  1.464675e+16          0           0\n",
       "        9978    3.089360e+16  3.089360e+16          0           0\n",
       "        2269    2.037520e+16  2.037520e+16          0           0\n",
       "        7591    3.474616e+16  3.474616e+16          0           0\n",
       "\n",
       "[25864 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
