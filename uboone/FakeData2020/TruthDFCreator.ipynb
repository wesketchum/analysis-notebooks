{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python tools loaded.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../../common/\")\n",
    "from python_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba.extending\n",
    "\n",
    "@numba.extending.overload(np.clip)\n",
    "def np_clip(a, a_min, a_max, out=None):\n",
    "    def np_clip_impl(a, a_min, a_max, out=None):\n",
    "        if out is None:\n",
    "            out = np.empty_like(a)\n",
    "        for i in range(len(a)):\n",
    "            if a[i] < a_min:\n",
    "                out[i] = a_min\n",
    "            elif a[i] > a_max:\n",
    "                out[i] = a_max\n",
    "            else:\n",
    "                out[i] = a[i]\n",
    "        return out\n",
    "    return np_clip_impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful functions\n",
    "# \n",
    "# you may need to comment out the 'numba' bits if your system can't install numba (like the gpvms...)\n",
    "#\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def costheta_numba(p1x,p1y,p1z,p1mag,\n",
    "                   p2x,p2y,p2z,p2mag):\n",
    "    return np.clip(np.where((p1mag>0.0)&(p2mag>0.0),\n",
    "                            (p1x*p2x+p1y*p2y+p1z*p2z)/p1mag/p2mag,\n",
    "                            np.nan),\n",
    "                   -1.0,1.0)\n",
    "\n",
    "def eval_costheta(df,suffix1=\"\",suffix2=\"\"):\n",
    "    return costheta_numba(df.loc[:,\"px\"+suffix1].values,df.loc[:,\"py\"+suffix1].values,df.loc[:,\"pz\"+suffix1].values,df.loc[:,\"p\"+suffix1].values,\n",
    "                          df.loc[:,\"px\"+suffix2].values,df.loc[:,\"py\"+suffix2].values,df.loc[:,\"pz\"+suffix2].values,df.loc[:,\"p\"+suffix2].values)\n",
    "\n",
    "    \n",
    "@numba.jit(nopython=True)\n",
    "def q3_numba(p1x,p1y,p1z,p2x,p2y,p2z):\n",
    "    return np.sqrt((p1x-p2x)**2+(p1y-p2y)**2+(p1z-p2z)**2)\n",
    "\n",
    "def eval_q3(df,suffix1=\"\",suffix2=\"_mu\"):\n",
    "    return q3_numba(df.loc[:,\"px\"+suffix1].values,df.loc[:,\"py\"+suffix1].values,df.loc[:,\"pz\"+suffix1].values,\n",
    "                    df.loc[:,\"px\"+suffix2].values,df.loc[:,\"py\"+suffix2].values,df.loc[:,\"pz\"+suffix2].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_files(sig_files,bkg_files,bkg_path,aa_run,aa_label,ac_run,ac_label):\n",
    "    for f in sig_files:\n",
    "        r = int(f.split(\"/\")[-1].split(\"_\")[-2])\n",
    "        sr = f.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "        run_set=\"\"\n",
    "        if(r==aa_run):\n",
    "            run_set=aa_label\n",
    "        if(r==ac_run):\n",
    "            run_set=ac_label\n",
    "    \n",
    "        fname = \"%s_%s/sampler_hist_%s.root\"%(bkg_path,run_set,sr)\n",
    "        try:\n",
    "            bkg_files.remove(fname)\n",
    "        except:\n",
    "            print(\"%s not found. (%s)\"%(fname,f))\n",
    "            sig_files.remove(f)\n",
    "    all_files = sig_files + bkg_files\n",
    "    return all_files,sig_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_filenames_Set1Run1_Sigs = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1_SignalFiles/*.root\")\n",
    "root_filenames_Set1Run1_Bkgs = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1_A[A,C]/*.root\")\n",
    "root_filenames_Set1Run3_Sigs = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run3_Sampler_Hists_Set1/Run3_SignalFiles/*.root\")\n",
    "root_filenames_Set1Run3_Bkgs = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run3_Sampler_Hists_Set1/Run3b_A[B,C]/*.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1_AC/sampler_hist_-1.root not found. (/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1_SignalFiles/sampler_hist_6693859_-1.root)\n"
     ]
    }
   ],
   "source": [
    "root_filenames_Set1Run1,root_filenames_Set1Run1_Sigs = remove_duplicate_files(root_filenames_Set1Run1_Sigs,\n",
    "                                                                              root_filenames_Set1Run1_Bkgs,\n",
    "                                                                              \"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run1_Sampler_Hists_Set1/Run1\",\n",
    "                                                                              6693842,\"AA\",6693859,\"AC\")\n",
    "root_filenames_Set1Run3,root_filenames_Set1Run3_Sigs = remove_duplicate_files(root_filenames_Set1Run3_Sigs,\n",
    "                                                                              root_filenames_Set1Run3_Bkgs,\n",
    "                                                                              \"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/Run3_Sampler_Hists_Set1/Run3b\",\n",
    "                                                                              7165574,\"AB\",7165592,\"AC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_filenames_CV   = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/CVSet/*/*/sampler*.root\")\n",
    "root_filenames_Set1 = root_filenames_Set1Run1+root_filenames_Set1Run3\n",
    "root_filenames_Set2 = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/*/*/sampler*.root\")\n",
    "root_filenames_Set3 = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set3/*/*/sampler*.root\")\n",
    "root_filenames_Set4 = glob.glob(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set4/*/*/sampler*.root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_root(root_filenames):\n",
    "    t_df = []\n",
    "    p_df = []\n",
    "    pot_df = []\n",
    "\n",
    "    file_count = 0\n",
    "    event_count = 0\n",
    "    print(\"Processing %d files\" % len(root_filenames))\n",
    "\n",
    "    for root_filename in root_filenames:\n",
    "    \n",
    "        try:\n",
    "            p_df.append(uproot.open(root_filename)['mcana/particle_tree'].pandas.df())\n",
    "            t_df.append(uproot.open(root_filename)['mcana/mctruth_tree'].pandas.df())\n",
    "            pot_df.append(uproot.open(root_filename)['potana/pot_tree'].pandas.df())\n",
    "        except:\n",
    "            print(\"File %s, trees not found.\"%root_filename)\n",
    "    \n",
    "        event_count += len(t_df[-1])\n",
    "        file_count += 1\n",
    "        if file_count%500==0:\n",
    "            print(\"\\tProcessed %d files. %d events processed.\" % (file_count,event_count))\n",
    "\n",
    "    p_df = pd.concat(p_df)\n",
    "    t_df = pd.concat(t_df)\n",
    "    pot_df = pd.concat(pot_df)\n",
    "\n",
    "    p_df.set_index([\"run\",\"subrun\",\"event\",\"truth_index\",\"p_index\"],inplace=True)\n",
    "    t_df.set_index([\"run\",\"subrun\",\"event\",\"truth_index\"],inplace=True)\n",
    "    pot_df.set_index([\"run\",\"subrun\"],inplace=True)\n",
    "        \n",
    "    print(\"Have dataframe objects. Total events is %d.\" % len(t_df))\n",
    "    \n",
    "    #make a ke column\n",
    "    p_df[\"ke\"] = p_df[\"e\"]-p_df[\"mass\"]\n",
    "    \n",
    "    return t_df,p_df,pot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finalstate_df(p_df):\n",
    "    df_n = pd.DataFrame()\n",
    "    \n",
    "    df_n[\"n_mu\"] = ((p_df[\"status\"]==1)&(p_df[\"pdgcode\"]==13)).replace(False,np.nan)\n",
    "    df_n[\"n_e\"] = ((p_df[\"status\"]==1)&(p_df[\"pdgcode\"]==11)).replace(False,np.nan)\n",
    "    df_n[\"n_p_40MeV\"] = ((p_df[\"status\"]==1)&(p_df[\"pdgcode\"]==2212)&((p_df[\"e\"]-p_df[\"mass\"])>0.03)).replace(False,np.nan)\n",
    "    df_n[\"n_pi0\"] = ((p_df[\"status\"]==1)&((p_df[\"pdgcode\"]==111))).replace(False,np.nan)\n",
    "    df_n[\"n_chpi\"] = ((p_df[\"status\"]==1)&((p_df[\"pdgcode\"]==211)^(p_df[\"pdgcode\"]==-211))).replace(False,np.nan)\n",
    "    df_n[\"n_gamma\"] = ((p_df[\"status\"]==1)&((p_df[\"pdgcode\"]==22))&(p_df[\"e\"]>0.02)).replace(False,np.nan)\n",
    "    df_n = df_n.groupby([\"run\",\"subrun\",\"event\",\"truth_index\"]).agg(\"sum\")\n",
    "    \n",
    "    return df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupings for final state protons (up to 4), pi0, gammas, and leptons. And initial neutrino.\n",
    "def group_particle_df(p_df):\n",
    "    p_df_p_grouped = p_df.query(\"status==1 and pdgcode==2212\").sort_values(by=[\"e\"],ascending=False).groupby([\"run\",\"subrun\",\"event\",\"truth_index\"])\n",
    "    p_df_p1 = p_df_p_grouped.nth(0)\n",
    "    p_df_p2 = p_df_p_grouped.nth(1)\n",
    "    p_df_p3 = p_df_p_grouped.nth(2)\n",
    "    p_df_p4 = p_df_p_grouped.nth(3)\n",
    "\n",
    "    p_df_pi0_grouped = p_df.query(\"status==1 and pdgcode==111\").sort_values(by=[\"e\"],ascending=False).groupby([\"run\",\"subrun\",\"event\",\"truth_index\"])\n",
    "    p_df_pi0 = p_df_pi0_grouped.nth(0)\n",
    "\n",
    "    p_df_gamma_grouped = p_df.query(\"status==1 and pdgcode==22\").sort_values(by=[\"e\"],ascending=False).groupby([\"run\",\"subrun\",\"event\",\"truth_index\"])\n",
    "    p_df_gamma = p_df_gamma_grouped.nth(0)\n",
    "\n",
    "    p_df_lep = p_df.query(\"status==1 and (pdgcode==13 or pdgcode==-13 or pdgcode==11 or pdgcode==-11 or pdgcode==12 or pdgcode==-12 or pdgcode==14 or pdgcode==-14)\").groupby([\"run\",\"subrun\",\"event\",\"truth_index\"]).first()\n",
    "    p_df_nu = p_df.query(\"status==0 and (pdgcode==12 or pdgcode==-12 or pdgcode==14 or pdgcode==-14)\").groupby([\"run\",\"subrun\",\"event\",\"truth_index\"]).first()\n",
    "    \n",
    "    return p_df_nu,p_df_lep,p_df_p1,p_df_p2,p_df_p3,p_df_p4,p_df_pi0,p_df_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_df_calcs(df_ev_t):\n",
    "    df_ev_t[\"costheta_lep\"] = eval_costheta(df=df_ev_t,suffix1=\"\",suffix2=\"_lep\")\n",
    "    df_ev_t[\"costheta_p1\"] = eval_costheta(df=df_ev_t,suffix1=\"\",suffix2=\"_p1\")\n",
    "    \n",
    "    return df_ev_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_event_df(t_df,p_df):\n",
    "    df_n = create_finalstate_df(p_df)\n",
    "    p_df_nu,p_df_lep,p_df_p1,p_df_p2,p_df_p3,p_df_p4,p_df_pi0,p_df_gamma = group_particle_df(p_df)\n",
    "    \n",
    "    df_ev_t = t_df.copy()\n",
    "    df_ev_t = df_ev_t.merge(p_df_nu,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_nu\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_lep,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_lep\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_p1,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_p1\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_p2,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_p2\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_p3,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_p3\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_p3,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_p4\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_pi0,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_pi0\"])\n",
    "    df_ev_t = df_ev_t.merge(p_df_gamma,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"],suffixes=[\"\",\"_gamma\"])\n",
    "    df_ev_t = df_ev_t.merge(df_n,how=\"left\",on=[\"run\",\"subrun\",\"event\",\"truth_index\"])\n",
    "    \n",
    "    df_ev_t = event_df_calcs(df_ev_t)\n",
    "    \n",
    "    return df_ev_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hdf(name,t_df,p_df,pot_df,df_ev_t):\n",
    "    t_df.to_hdf(name,\"t_df\")\n",
    "    p_df.to_hdf(name,\"p_df\")\n",
    "    pot_df.to_hdf(name,\"pot_df\")\n",
    "    df_ev_t.to_hdf(name,\"ev_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 39991 files\n",
      "\tProcessed 500 files. 10928 events processed.\n",
      "\tProcessed 1000 files. 22040 events processed.\n",
      "\tProcessed 1500 files. 32944 events processed.\n",
      "\tProcessed 2000 files. 44097 events processed.\n",
      "\tProcessed 2500 files. 55145 events processed.\n",
      "\tProcessed 3000 files. 66415 events processed.\n",
      "\tProcessed 3500 files. 77565 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/CVSet/Run3/AB/sampler_hist_6106.root, trees not found.\n",
      "\tProcessed 4000 files. 88617 events processed.\n",
      "\tProcessed 4500 files. 99795 events processed.\n",
      "\tProcessed 5000 files. 110985 events processed.\n",
      "\tProcessed 5500 files. 121751 events processed.\n",
      "\tProcessed 6000 files. 132932 events processed.\n",
      "\tProcessed 6500 files. 143947 events processed.\n",
      "\tProcessed 7000 files. 154966 events processed.\n",
      "\tProcessed 7500 files. 166007 events processed.\n",
      "\tProcessed 8000 files. 177046 events processed.\n",
      "\tProcessed 8500 files. 188162 events processed.\n",
      "\tProcessed 9000 files. 199311 events processed.\n",
      "\tProcessed 9500 files. 210186 events processed.\n",
      "\tProcessed 10000 files. 221301 events processed.\n",
      "\tProcessed 10500 files. 231333 events processed.\n",
      "\tProcessed 11000 files. 241784 events processed.\n",
      "\tProcessed 11500 files. 252135 events processed.\n",
      "\tProcessed 12000 files. 262496 events processed.\n",
      "\tProcessed 12500 files. 272633 events processed.\n",
      "\tProcessed 13000 files. 282835 events processed.\n",
      "\tProcessed 13500 files. 293206 events processed.\n",
      "\tProcessed 14000 files. 303418 events processed.\n",
      "\tProcessed 14500 files. 313494 events processed.\n",
      "\tProcessed 15000 files. 323728 events processed.\n",
      "\tProcessed 15500 files. 334058 events processed.\n",
      "\tProcessed 16000 files. 344152 events processed.\n",
      "\tProcessed 16500 files. 354692 events processed.\n",
      "\tProcessed 17000 files. 364911 events processed.\n",
      "\tProcessed 17500 files. 375197 events processed.\n",
      "\tProcessed 18000 files. 385285 events processed.\n",
      "\tProcessed 18500 files. 395449 events processed.\n",
      "\tProcessed 19000 files. 405586 events processed.\n",
      "\tProcessed 19500 files. 416012 events processed.\n",
      "\tProcessed 20000 files. 426254 events processed.\n",
      "\tProcessed 20500 files. 438737 events processed.\n",
      "\tProcessed 21000 files. 451029 events processed.\n",
      "\tProcessed 21500 files. 463241 events processed.\n",
      "\tProcessed 22000 files. 475437 events processed.\n",
      "\tProcessed 22500 files. 487748 events processed.\n",
      "\tProcessed 23000 files. 500242 events processed.\n",
      "\tProcessed 23500 files. 512564 events processed.\n",
      "\tProcessed 24000 files. 524973 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/CVSet/Run1/AB/sampler_hist_4947.root, trees not found.\n",
      "\tProcessed 24500 files. 537448 events processed.\n",
      "\tProcessed 25000 files. 549529 events processed.\n",
      "\tProcessed 25500 files. 561929 events processed.\n",
      "\tProcessed 26000 files. 574459 events processed.\n",
      "\tProcessed 26500 files. 586720 events processed.\n",
      "\tProcessed 27000 files. 599066 events processed.\n",
      "\tProcessed 27500 files. 611321 events processed.\n",
      "\tProcessed 28000 files. 623665 events processed.\n",
      "\tProcessed 28500 files. 635966 events processed.\n",
      "\tProcessed 29000 files. 648212 events processed.\n",
      "\tProcessed 29500 files. 660345 events processed.\n",
      "\tProcessed 30000 files. 672711 events processed.\n",
      "\tProcessed 30500 files. 678758 events processed.\n",
      "\tProcessed 31000 files. 684861 events processed.\n",
      "\tProcessed 31500 files. 691039 events processed.\n",
      "\tProcessed 32000 files. 697027 events processed.\n",
      "\tProcessed 32500 files. 703125 events processed.\n",
      "\tProcessed 33000 files. 709338 events processed.\n",
      "\tProcessed 33500 files. 715376 events processed.\n",
      "\tProcessed 34000 files. 721248 events processed.\n",
      "\tProcessed 34500 files. 727313 events processed.\n",
      "\tProcessed 35000 files. 733460 events processed.\n",
      "\tProcessed 35500 files. 739547 events processed.\n",
      "\tProcessed 36000 files. 745651 events processed.\n",
      "\tProcessed 36500 files. 751650 events processed.\n",
      "\tProcessed 37000 files. 757655 events processed.\n",
      "\tProcessed 37500 files. 763864 events processed.\n",
      "\tProcessed 38000 files. 770160 events processed.\n",
      "\tProcessed 38500 files. 776256 events processed.\n",
      "\tProcessed 39000 files. 782292 events processed.\n",
      "\tProcessed 39500 files. 788367 events processed.\n",
      "Have dataframe objects. Total events is 794435.\n"
     ]
    }
   ],
   "source": [
    "t_df,p_df,pot_df = convert_root(root_filenames_CV)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/CVSet/mcana_dfs.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 28537 files\n",
      "\tProcessed 500 files. 8291 events processed.\n",
      "\tProcessed 1000 files. 13640 events processed.\n",
      "\tProcessed 1500 files. 19017 events processed.\n",
      "\tProcessed 2000 files. 24375 events processed.\n",
      "\tProcessed 2500 files. 29770 events processed.\n",
      "\tProcessed 3000 files. 35127 events processed.\n",
      "\tProcessed 3500 files. 40520 events processed.\n",
      "\tProcessed 4000 files. 45720 events processed.\n",
      "\tProcessed 4500 files. 51118 events processed.\n",
      "\tProcessed 5000 files. 56442 events processed.\n",
      "\tProcessed 5500 files. 61894 events processed.\n",
      "\tProcessed 6000 files. 67304 events processed.\n",
      "\tProcessed 6500 files. 72531 events processed.\n",
      "\tProcessed 7000 files. 77882 events processed.\n",
      "\tProcessed 7500 files. 83228 events processed.\n",
      "\tProcessed 8000 files. 88671 events processed.\n",
      "\tProcessed 8500 files. 94279 events processed.\n",
      "\tProcessed 9000 files. 99562 events processed.\n",
      "\tProcessed 9500 files. 104917 events processed.\n",
      "\tProcessed 10000 files. 110309 events processed.\n",
      "\tProcessed 10500 files. 119544 events processed.\n",
      "\tProcessed 11000 files. 129225 events processed.\n",
      "\tProcessed 11500 files. 138901 events processed.\n",
      "\tProcessed 12000 files. 148559 events processed.\n",
      "\tProcessed 12500 files. 158242 events processed.\n",
      "\tProcessed 13000 files. 167913 events processed.\n",
      "\tProcessed 13500 files. 177554 events processed.\n",
      "\tProcessed 14000 files. 187238 events processed.\n",
      "\tProcessed 14500 files. 196910 events processed.\n",
      "\tProcessed 15000 files. 206603 events processed.\n",
      "\tProcessed 15500 files. 216421 events processed.\n",
      "\tProcessed 16000 files. 226007 events processed.\n",
      "\tProcessed 16500 files. 235255 events processed.\n",
      "\tProcessed 17000 files. 244663 events processed.\n",
      "\tProcessed 17500 files. 253765 events processed.\n",
      "\tProcessed 18000 files. 263484 events processed.\n",
      "\tProcessed 18500 files. 272842 events processed.\n",
      "\tProcessed 19000 files. 282296 events processed.\n",
      "\tProcessed 19500 files. 291960 events processed.\n",
      "\tProcessed 20000 files. 301533 events processed.\n",
      "\tProcessed 20500 files. 311265 events processed.\n",
      "\tProcessed 21000 files. 320690 events processed.\n",
      "\tProcessed 21500 files. 330653 events processed.\n",
      "\tProcessed 22000 files. 340385 events processed.\n",
      "\tProcessed 22500 files. 350027 events processed.\n",
      "\tProcessed 23000 files. 359690 events processed.\n",
      "\tProcessed 23500 files. 369362 events processed.\n",
      "\tProcessed 24000 files. 378806 events processed.\n",
      "\tProcessed 24500 files. 388520 events processed.\n",
      "\tProcessed 25000 files. 398172 events processed.\n",
      "\tProcessed 25500 files. 407755 events processed.\n",
      "\tProcessed 26000 files. 417398 events processed.\n",
      "\tProcessed 26500 files. 427051 events processed.\n",
      "\tProcessed 27000 files. 436663 events processed.\n",
      "\tProcessed 27500 files. 446401 events processed.\n",
      "\tProcessed 28000 files. 455849 events processed.\n",
      "\tProcessed 28500 files. 465460 events processed.\n",
      "Have dataframe objects. Total events is 466225.\n"
     ]
    }
   ],
   "source": [
    "t_df,p_df,pot_df = convert_root(root_filenames_Set1)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set1/mcana_dfs.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 48390 files\n",
      "\tProcessed 500 files. 9045 events processed.\n",
      "\tProcessed 1000 files. 18303 events processed.\n",
      "\tProcessed 1500 files. 27356 events processed.\n",
      "\tProcessed 2000 files. 36163 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/Run3/32044093_1706/sampler_hist_1706.root, trees not found.\n",
      "\tProcessed 2500 files. 45546 events processed.\n",
      "\tProcessed 3000 files. 54681 events processed.\n",
      "\tProcessed 3500 files. 63953 events processed.\n",
      "\tProcessed 4000 files. 73347 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/Run3/32044121_1183/sampler_hist_1183.root, trees not found.\n",
      "\tProcessed 4500 files. 82819 events processed.\n",
      "\tProcessed 5000 files. 92318 events processed.\n",
      "\tProcessed 5500 files. 101552 events processed.\n",
      "\tProcessed 6000 files. 110767 events processed.\n",
      "\tProcessed 6500 files. 120243 events processed.\n",
      "\tProcessed 7000 files. 129437 events processed.\n",
      "\tProcessed 7500 files. 138944 events processed.\n",
      "\tProcessed 8000 files. 148457 events processed.\n",
      "\tProcessed 8500 files. 157632 events processed.\n",
      "\tProcessed 9000 files. 166691 events processed.\n",
      "\tProcessed 9500 files. 175882 events processed.\n",
      "\tProcessed 10000 files. 184814 events processed.\n",
      "\tProcessed 10500 files. 194076 events processed.\n",
      "\tProcessed 11000 files. 203071 events processed.\n",
      "\tProcessed 11500 files. 212379 events processed.\n",
      "\tProcessed 12000 files. 221737 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/Run3/32044093_3803/sampler_hist_3803.root, trees not found.\n",
      "\tProcessed 12500 files. 230958 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/Run3/32044093_4044/sampler_hist_4044.root, trees not found.\n",
      "\tProcessed 13000 files. 239974 events processed.\n",
      "\tProcessed 13500 files. 249080 events processed.\n",
      "\tProcessed 14000 files. 258052 events processed.\n",
      "\tProcessed 14500 files. 267201 events processed.\n",
      "\tProcessed 15000 files. 276518 events processed.\n",
      "\tProcessed 15500 files. 285647 events processed.\n",
      "\tProcessed 16000 files. 294932 events processed.\n",
      "\tProcessed 16500 files. 304032 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/Run3/32044041_4772/sampler_hist_4772.root, trees not found.\n",
      "\tProcessed 17000 files. 313434 events processed.\n",
      "\tProcessed 17500 files. 322580 events processed.\n",
      "\tProcessed 18000 files. 331937 events processed.\n",
      "\tProcessed 18500 files. 341131 events processed.\n",
      "\tProcessed 19000 files. 350528 events processed.\n",
      "\tProcessed 19500 files. 359698 events processed.\n",
      "\tProcessed 20000 files. 369082 events processed.\n",
      "\tProcessed 20500 files. 378458 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/Run3/32044093_611/sampler_hist_611.root, trees not found.\n",
      "\tProcessed 21000 files. 387498 events processed.\n",
      "\tProcessed 21500 files. 396472 events processed.\n",
      "\tProcessed 22000 files. 405612 events processed.\n",
      "\tProcessed 22500 files. 414725 events processed.\n",
      "\tProcessed 23000 files. 423955 events processed.\n",
      "\tProcessed 23500 files. 432147 events processed.\n",
      "\tProcessed 24000 files. 440123 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/Run1/32043925_6258/sampler_hist_6258.root, trees not found.\n",
      "\tProcessed 24500 files. 448478 events processed.\n",
      "\tProcessed 25000 files. 456856 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/Run1/32043865_5706/sampler_hist_5706.root, trees not found.\n",
      "\tProcessed 25500 files. 464937 events processed.\n",
      "\tProcessed 26000 files. 473216 events processed.\n",
      "\tProcessed 26500 files. 481525 events processed.\n",
      "\tProcessed 27000 files. 489664 events processed.\n",
      "\tProcessed 27500 files. 497796 events processed.\n",
      "\tProcessed 28000 files. 506177 events processed.\n",
      "\tProcessed 28500 files. 514363 events processed.\n",
      "\tProcessed 29000 files. 522584 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/Run1/32043865_1009/sampler_hist_1009.root, trees not found.\n",
      "\tProcessed 29500 files. 530987 events processed.\n",
      "\tProcessed 30000 files. 539301 events processed.\n",
      "\tProcessed 30500 files. 547337 events processed.\n",
      "\tProcessed 31000 files. 555585 events processed.\n",
      "\tProcessed 31500 files. 564141 events processed.\n",
      "\tProcessed 32000 files. 572425 events processed.\n",
      "\tProcessed 32500 files. 580605 events processed.\n",
      "\tProcessed 33000 files. 589148 events processed.\n",
      "\tProcessed 33500 files. 597341 events processed.\n",
      "\tProcessed 34000 files. 605686 events processed.\n",
      "\tProcessed 34500 files. 613973 events processed.\n",
      "\tProcessed 35000 files. 622124 events processed.\n",
      "\tProcessed 35500 files. 630340 events processed.\n",
      "\tProcessed 36000 files. 638355 events processed.\n",
      "\tProcessed 36500 files. 646746 events processed.\n",
      "\tProcessed 37000 files. 655067 events processed.\n",
      "\tProcessed 37500 files. 663069 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/Run1/32043925_9018/sampler_hist_9018.root, trees not found.\n",
      "\tProcessed 38000 files. 671293 events processed.\n",
      "\tProcessed 38500 files. 679729 events processed.\n",
      "\tProcessed 39000 files. 687808 events processed.\n",
      "\tProcessed 39500 files. 696296 events processed.\n",
      "\tProcessed 40000 files. 704621 events processed.\n",
      "\tProcessed 40500 files. 712731 events processed.\n",
      "\tProcessed 41000 files. 721269 events processed.\n",
      "\tProcessed 41500 files. 729679 events processed.\n",
      "\tProcessed 42000 files. 737747 events processed.\n",
      "\tProcessed 42500 files. 746045 events processed.\n",
      "\tProcessed 43000 files. 754157 events processed.\n",
      "\tProcessed 43500 files. 762390 events processed.\n",
      "\tProcessed 44000 files. 770519 events processed.\n",
      "\tProcessed 44500 files. 778745 events processed.\n",
      "\tProcessed 45000 files. 786805 events processed.\n",
      "\tProcessed 45500 files. 795012 events processed.\n",
      "\tProcessed 46000 files. 803081 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/Run1/32043865_1311/sampler_hist_1311.root, trees not found.\n",
      "\tProcessed 46500 files. 811449 events processed.\n",
      "\tProcessed 47000 files. 819530 events processed.\n",
      "\tProcessed 47500 files. 827579 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/Run1/32043865_9977/sampler_hist_9977.root, trees not found.\n",
      "\tProcessed 48000 files. 835951 events processed.\n",
      "Have dataframe objects. Total events is 842367.\n"
     ]
    }
   ],
   "source": [
    "t_df,p_df,pot_df = convert_root(root_filenames_Set2)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set2/mcana_dfs.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 48505 files\n",
      "\tProcessed 500 files. 8557 events processed.\n",
      "\tProcessed 1000 files. 17345 events processed.\n",
      "\tProcessed 1500 files. 26125 events processed.\n",
      "\tProcessed 2000 files. 34915 events processed.\n",
      "\tProcessed 2500 files. 43301 events processed.\n",
      "\tProcessed 3000 files. 52078 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set3/Run3/31873900_6782/sampler_hist_6782.root, trees not found.\n",
      "\tProcessed 3500 files. 60427 events processed.\n",
      "\tProcessed 4000 files. 69069 events processed.\n",
      "\tProcessed 4500 files. 77436 events processed.\n",
      "File /Users/wketchum/Data/MicroBooNE/FakeData2020/Set3/Run3/7265654_7040/sampler_hist_7040.root, trees not found.\n",
      "\tProcessed 5000 files. 85995 events processed.\n",
      "\tProcessed 5500 files. 94359 events processed.\n",
      "\tProcessed 6000 files. 102968 events processed.\n",
      "\tProcessed 6500 files. 111575 events processed.\n"
     ]
    }
   ],
   "source": [
    "t_df,p_df,pot_df = convert_root(root_filenames_Set3)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set3/mcana_dfs.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df,p_df,pot_df = convert_root(root_filenames_Set4)\n",
    "ev_df = create_event_df(t_df,p_df)\n",
    "write_hdf(\"/Users/wketchum/Data/MicroBooNE/FakeData2020/Set4/mcana_dfs.h5\",\n",
    "          t_df,p_df,pot_df,ev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
