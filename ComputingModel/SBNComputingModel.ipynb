{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Process:\n",
    "    \n",
    "    def set_name(self,name):\n",
    "        self.name = name\n",
    "        \n",
    "    def set_memory_MB(self,memory_MB):\n",
    "        self.memory_MB = memory_MB\n",
    "        \n",
    "    def set_time_s(self,time_s):\n",
    "        self.time_s = time_s\n",
    "        \n",
    "    def set_input_size_MB(self,input_MB):\n",
    "        self.input_size_MB = input_MB\n",
    "        \n",
    "    def set_output_size_MB(self,output_MB):\n",
    "        self.output_size_MB = output_MB\n",
    "    \n",
    "    def set_threads(self,min_threads,max_threads=None):\n",
    "        self.min_threads = min_threads\n",
    "        if max_threads:\n",
    "            self.max_threads = max_threads\n",
    "        else:\n",
    "            self.max_threads = min_threads\n",
    "    \n",
    "    def set_pass_fraction(self,pass_fraction):\n",
    "        self.pass_fraction = pass_fraction\n",
    "        \n",
    "    def set_failure_rate(self,failure_rate):\n",
    "        self.failure_rate = failure_rate\n",
    "    \n",
    "    def __init__(self,\n",
    "                 memory_MB=0,time_s=0,\n",
    "                 input_MB=0,output_MB=0,\n",
    "                 name=\"\",\n",
    "                 min_threads=1,max_threads=None,\n",
    "                 pass_fraction=1.0,\n",
    "                 failure_rate=0.0):\n",
    "\n",
    "        self.set_name(name)\n",
    "        \n",
    "        self.set_memory_MB(memory_MB)\n",
    "        self.set_time_s(time_s)\n",
    "        \n",
    "        self.set_input_size_MB(input_MB)\n",
    "        self.set_output_size_MB(output_MB)\n",
    "        \n",
    "        self.set_threads(min_threads,max_threads)\n",
    "\n",
    "        self.set_pass_fraction(pass_fraction)\n",
    "        self.set_failure_rate(failure_rate)\n",
    "\n",
    "    def __str__(self):\n",
    "        s = \"Process '%s':\"%self.name\n",
    "        s = s+\"\\n\\tMemory (MB): %f\"%self.memory_MB\n",
    "        s = s+\"\\n\\tTime per event (s): %f\"%self.time_s\n",
    "        s = s+\"\\n\\tInput/Output size per event (MB): %f / %f\"%(self.input_size_MB,self.output_size_MB)\n",
    "        s = s+\"\\n\\tThreads used (min,max): (%d,%d)\"%(self.min_threads,self.max_threads)\n",
    "        s = s+\"\\n\\tEvent pass fraction: %f\"%self.pass_fraction\n",
    "        s = s+\"\\n\\tFailure rate: %f\"%self.failure_rate\n",
    "        return s\n",
    "        \n",
    "def ChainProcesses(processes,name=\"\"):\n",
    "    \n",
    "    if len(processes)==0:\n",
    "        print(\"Process list length 0. Return empty Process.\")\n",
    "        return Process()\n",
    "    \n",
    "    max_memory = np.max([p.memory_MB for p in processes])\n",
    "\n",
    "    time_s = processes[0].time_s\n",
    "    for i in range(1,len(processes)):\n",
    "        time_s += np.prod([p.pass_fraction for p in processes[0:i]])*processes[i].time_s\n",
    "    \n",
    "    input_size_MB = processes[0].input_size_MB\n",
    "    max_input_size = np.max([p.input_size_MB for p in processes])\n",
    "    if input_size_MB < max_input_size:\n",
    "        print(\"WARNING! First process input size (%f) is less than max input size (%f).\\nSetting max to %f MB\"%\n",
    "              (input_size_MB,max_input_size,max_input_size))\n",
    "        input_size_MB=max_input_size\n",
    "            \n",
    "    min_threads = np.max([p.min_threads for p in processes])\n",
    "    max_threads = np.max([p.max_threads for p in processes])\n",
    "    \n",
    "    pass_fraction = np.prod([p.pass_fraction for p in processes])\n",
    "    failure_rate = 1. - np.prod([(1.- p.failure_rate) for p in processes])\n",
    "    \n",
    "    output_size_MB = processes[-1].output_size_MB*pass_fraction\n",
    "\n",
    "    return Process(memory_MB=max_memory,time_s=time_s,\n",
    "                   name=name,\n",
    "                   input_MB=input_size_MB,output_MB=output_size_MB,\n",
    "                   min_threads=min_threads,max_threads=max_threads,\n",
    "                   pass_fraction=pass_fraction,failure_rate=failure_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIOInterface:\n",
    "    \n",
    "    def set_name(self,name):\n",
    "        self.name = name\n",
    "\n",
    "    def set_rate_MBps(self,rate_MBps):\n",
    "        self.rate_MBps = rate_MBps\n",
    "    \n",
    "    def __init__(self,\n",
    "                 name=\"\",\n",
    "                 rate_MBps=np.inf):\n",
    "        \n",
    "        self.set_name(name)\n",
    "        self.set_rate_MBps(rate_MBps)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job:\n",
    "    \n",
    "    DEFAULT_INTERFACE = DataIOInterface(name=\"Default\",rate_MBps=np.inf)\n",
    "    \n",
    "    def set_process(self,process,recompute=True):\n",
    "        if type(process) is list:\n",
    "            process = ChainProcesses(process)\n",
    "        self.process=process\n",
    "        if recompute: self.recompute()\n",
    "        \n",
    "    def set_n_events(self,n_events,recompute=True):\n",
    "        self.n_events = n_events\n",
    "        if recompute: self.recompute()\n",
    "        \n",
    "    def recompute(self):\n",
    "        self.memory_MB = self.process.memory_MB\n",
    "        self.cpu_time_s = self.process.time_s * self.n_events\n",
    "\n",
    "        self.input_size_MB = self.process.input_size_MB * self.n_events\n",
    "        self.input_time_s = self.input_size_MB / self.input_interface.rate_MBps\n",
    "        \n",
    "        self.output_size_MB = self.process.output_size_MB * self.n_events * self.process.pass_fraction\n",
    "        self.output_time_s = self.output_size_MB / self.output_interface.rate_MBps\n",
    "        \n",
    "        self.io_time_s = self.input_time_s + self.output_time_s\n",
    "        self.total_time_s = self.cpu_time_s + self.io_time_s        \n",
    "        \n",
    "        self.pass_fraction = self.process.pass_fraction\n",
    "        self.failure_rate = 1. - np.power((1.-self.process.failure_rate),self.n_events)\n",
    "    \n",
    "    def set_input_interface(self,input_interface,recompute=True):\n",
    "        self.input_interface=input_interface\n",
    "        if recompute: self.recompute()\n",
    "    \n",
    "    def set_output_interface(self,output_interface,recompute=True):\n",
    "        self.output_interface=output_interface\n",
    "        if recompute: self.recompute()\n",
    "\n",
    "    def __init__(self,\n",
    "                 process,\n",
    "                 input_interface=DEFAULT_INTERFACE,\n",
    "                 output_interface=DEFAULT_INTERFACE,\n",
    "                 n_events=100):\n",
    "        \n",
    "        self.set_process(process,recompute=False)\n",
    "        self.set_n_events(n_events,recompute=False)\n",
    "\n",
    "        self.set_input_interface(input_interface,recompute=False)\n",
    "        self.set_output_interface(output_interface,recompute=False)\n",
    "        \n",
    "        self.recompute()\n",
    "        \n",
    "    def __str__(self):\n",
    "        s = \"Process: '%s':\"%self.process.name\n",
    "        s = s+\"\\nN_Events: %d\"%self.n_events\n",
    "        s = s+\"\\nMemory (MB): %f\"%(self.memory_MB)\n",
    "        s = s+\"\\nTime (hr): %f\"%(self.total_time_s/3600.)\n",
    "        s = s+\"\\n\\tCPU Time (hr): %f\"%(self.cpu_time_s/3600.)\n",
    "        s = s+\"\\n\\tIO Time (hr): %f\"%(self.io_time_s/3600.)\n",
    "        s = s+\"\\nEvent pass fraction: %f\"%self.pass_fraction\n",
    "        s = s+\"\\nInput/Output size (GB): %f / %f\"%(self.input_size_MB/1000.,self.output_size_MB/1000.)\n",
    "        s = s+\"\\nFailure rate: %f\"%self.failure_rate\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    \n",
    "    def set_name(self,name):\n",
    "        self.name = name\n",
    "\n",
    "    def set_job(self,job,recompute=True):\n",
    "        self.job = copy.copy(job)\n",
    "        if recompute: \n",
    "            self.set_events_and_jobs(n_events=self.n_events,\n",
    "                                    n_jobs=self.n_jobs)\n",
    "            self.recompute()\n",
    "        \n",
    "    def set_events_and_jobs(self,n_events,n_jobs,recompute=True):\n",
    "\n",
    "        if n_events is None and n_jobs is None:\n",
    "            print(\"Must specify either n_jobs or n_events.\")\n",
    "            return\n",
    "\n",
    "        #Both events and jobs specified\n",
    "        #Update events per job\n",
    "        elif n_events is not None and n_jobs is not None:\n",
    "        \n",
    "            self.n_events = n_events\n",
    "            self.n_events_per_job = n_events/n_jobs\n",
    "            self.n_jobs = self.n_events / self.n_events_per_job\n",
    "                \n",
    "            self.job.set_n_events(n_events=self.n_events_per_job,recompute=True)\n",
    "            \n",
    "        #Only n_events is specified.\n",
    "        #Calc necessary number of jobs based on job.n_events\n",
    "        elif n_events is not None and n_jobs is None:\n",
    "            self.n_events_per_job = self.job.n_events\n",
    "            self.n_jobs = n_events / self.n_events_per_job\n",
    "            self.n_events = self.n_jobs*self.n_events_per_job\n",
    "        \n",
    "        #Only number of jobs is specified.\n",
    "        #Calculate number of events based on job.n_events\n",
    "        elif n_events is None and n_jobs is not None:\n",
    "            self.n_events_per_job = self.job.n_events\n",
    "            self.n_jobs = n_jobs\n",
    "            self.n_events = self.n_jobs*self.n_events_per_job\n",
    "\n",
    "        else:\n",
    "            print(\"Error: Unknown condition.\")\n",
    "            return\n",
    "        \n",
    "        #Check/tell user if some recalcs happened\n",
    "        if self.n_events!=n_events or self.n_jobs!=n_jobs:\n",
    "            print(\"Requested n_events=\",n_events,\" with n_jobs=\",n_jobs)\n",
    "            print(\"Setting n_events=%d with n_jobs=%d\"%(self.n_events,self.n_jobs))\n",
    "            \n",
    "        if recompute: self.recompute()\n",
    "    \n",
    "    \n",
    "    def recompute(self,time_complete_days=None,max_slots=None):\n",
    "        \n",
    "        self.input_size_MB = self.n_events*self.job.process.input_size_MB\n",
    "        self.output_size_MB = self.n_events*self.job.process.output_size_MB\n",
    "        \n",
    "        self.input_time_s = self.input_size_MB / self.job.input_interface.rate_MBps\n",
    "        self.output_time_s = self.output_size_MB / self.job.output_interface.rate_MBps\n",
    "        \n",
    "        self.cpu_time_s = float(self.job.cpu_time_s * self.n_jobs)\n",
    "        self.slot_weight = self.job.memory_MB / 2000.\n",
    "        \n",
    "        input_time_days = self.input_time_s/3600./24.\n",
    "        output_time_days = self.output_time_s/3600./24.\n",
    "        print(\"%f %f\"%(input_time_days,output_time_days))\n",
    "        \n",
    "        #If completion time set, calculate peak slots needed\n",
    "        if time_complete_days is not None:\n",
    "            self.time_complete_days = float(time_complete_days)\n",
    "            self.bound = \"COMPUTE\"\n",
    "            \n",
    "            #check if possible given input data rate\n",
    "            if input_time_days>self.time_complete_days:\n",
    "                needed_input_rate = self.job.input_interface.rate_MBps * input_time_days/self.time_complete_days\n",
    "                \n",
    "                print(\"Time to input data exceeds desired completion time: %f > %f\"%(input_time_days,self.time_complete_days))\n",
    "                print(\"Input rate needed is %f MBps (vs. specified %f MBps)\"%(needed_input_rate,self.job.input_interface.rate_MBps))\n",
    "                print(\"Increasing completion time to %f\"%input_time_days)\n",
    "                \n",
    "                self.time_complete_days = input_time_days\n",
    "                self.bound = \"INPUT\"\n",
    "\n",
    "            #check if possible given output data rate\n",
    "            if output_time_days>self.time_complete_days:\n",
    "                needed_output_rate = self.job.output_interface.rate_MBps * output_time_days/self.time_complete_days\n",
    "                \n",
    "                print(\"Time to input data exceeds desired completion time: %f > %f\"%(output_time_days,time_complete_days))\n",
    "                print(\"Output rate needed is %f MBps (vs. specified %f MBps)\"%(needed_output_rate,self.job.output_interface.rate_MBps))\n",
    "                print(\"Increasing completion time to %f\"%output_time_days)\n",
    "                \n",
    "                self.time_complete_days = output_time_days\n",
    "                self.bound = \"OUTPUT\"\n",
    "                \n",
    "            self.peak_slots = self.slot_weight*((self.cpu_time_s/3600./24.)/self.time_complete_days)\n",
    "            \n",
    "        elif max_slots is not None:\n",
    "            self.peak_slots = max_slots\n",
    "            \n",
    "            compute_time_days = (self.cpu_time_s/3600./24.)/(self.peak_slots/self.slot_weight)\n",
    "            print(\"%f %f %f\"%(compute_time_days,input_time_days,output_time_days))\n",
    "\n",
    "            if compute_time_days>input_time_days and compute_time_days>output_time_days:\n",
    "                self.bound=\"COMPUTE\"\n",
    "                self.time_complete_days = compute_time_days\n",
    "            elif input_time_days>=output_time_days:\n",
    "                self.bound=\"INPUT\"\n",
    "                self.time_complete_days = input_time_days\n",
    "                self.peak_slots = self.slot_weight*(self.time_complete_days / (self.cpu_time_s/3600./24.))\n",
    "            elif output_time_days>input_time_days:\n",
    "                self.bound=\"OUTPUT\"\n",
    "                self.time_complete_days = output_time_days\n",
    "                self.peak_slots = self.slot_weight*(self.time_complete_days / (self.cpu_time_s/3600./24.))\n",
    "                \n",
    "            if self.peak_slots < max_slots:\n",
    "                print(\"Process is %s bound, and so uses only %d of available %d slots.\"%(self.bound,self.peak_slots,max_slots))\n",
    "                \n",
    "        return\n",
    "    \n",
    "    def __init__(self,\n",
    "                 job,\n",
    "                 name=\"\",\n",
    "                 n_events=None,n_jobs=None,\n",
    "                 time_complete_days=None,max_slots=None):\n",
    "        \n",
    "        if n_events is None and n_jobs is None:\n",
    "            print(\"Must specify either n_jobs or n_events.\")\n",
    "            return\n",
    "        \n",
    "        if time_complete_days is None and max_slots is None:\n",
    "            print(\"Must specify either time_complete_days or max_slots.\")\n",
    "            return\n",
    "        \n",
    "        self.set_name(name)\n",
    "        self.set_job(job,recompute=False)\n",
    "        self.set_events_and_jobs(n_events,n_jobs,recompute=False)\n",
    "\n",
    "        self.recompute(time_complete_days=time_complete_days,\n",
    "                       max_slots=max_slots)\n",
    "        \n",
    "        \n",
    "    def __str__(self):\n",
    "        s = \"Sample '%s':\"%self.name\n",
    "        s = s+\"\\nN_Events: %d\"%self.n_events\n",
    "        s = s+\"\\nN_Jobs: %d\"%self.n_jobs\n",
    "        s = s+\"\\nN_Events_per_job: %d\"%self.n_events_per_job\n",
    "        s = s+\"\\nInput Datset Size (TB): %f\"%(self.input_size_MB/1000./1000.)\n",
    "        s = s+\"\\nOutput Datset Size (TB): %f\"%(self.output_size_MB/1000./1000.)\n",
    "        s = s+\"\\nCompletion Time (days): %f\"%(self.time_complete_days)\n",
    "        s = s+\"\\n\\tCPU Time (hr): %f\"%(self.cpu_time_s/3600.)\n",
    "        s = s+\"\\n\\tWeighted CPU Time (hr): %f\"%(self.cpu_time_s/3600.*self.slot_weight)\n",
    "        s = s+\"\\nPeak slots: %d\"%self.peak_slots\n",
    "        s = s+\"\\nBound: %s\"%self.bound\n",
    "        return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Process(name=\"unnamed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 'unnamed'\n",
      "\tMemory (MB): 0.000000\n",
      "\tTime per event (s): 0.000000\n",
      "\tInput/Output size per event (MB): 0.000000 / 0.000000\n",
      "\tThreads used (min,max): (1,1)\n",
      "\tEvent pass fraction: 1.000000\n",
      "\tFailure rate: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "icarus_data_reco1 = Process(name=\"ICARUS Data Stage0\",\n",
    "                           memory_MB=4000,\n",
    "                           time_s=120,\n",
    "                           input_MB=170,\n",
    "                           output_MB=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "icarus_data_reco2 = Process(name=\"ICARUS Data Stage1\",\n",
    "                           memory_MB=4000,\n",
    "                           time_s=100,\n",
    "                           input_MB=50,\n",
    "                           output_MB=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 'ICARUS Data Stage0':\n",
      "\tMemory (MB): 4000.000000\n",
      "\tTime per event (s): 120.000000\n",
      "\tInput/Output size per event (MB): 170.000000 / 50.000000\n",
      "\tThreads used (min,max): (1,1)\n",
      "\tEvent pass fraction: 1.000000\n",
      "\tFailure rate: 0.000000\n",
      "Process 'ICARUS Data Stage1':\n",
      "\tMemory (MB): 4000.000000\n",
      "\tTime per event (s): 100.000000\n",
      "\tInput/Output size per event (MB): 50.000000 / 45.000000\n",
      "\tThreads used (min,max): (1,1)\n",
      "\tEvent pass fraction: 1.000000\n",
      "\tFailure rate: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(icarus_data_reco1)\n",
    "print(icarus_data_reco2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "icarus_data_reco = ChainProcesses([icarus_data_reco1,icarus_data_reco2],\"ICARUS Data Reco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 'ICARUS Data Reco':\n",
      "\tMemory (MB): 4000.000000\n",
      "\tTime per event (s): 220.000000\n",
      "\tInput/Output size per event (MB): 170.000000 / 45.000000\n",
      "\tThreads used (min,max): (1,1)\n",
      "\tEvent pass fraction: 1.000000\n",
      "\tFailure rate: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(icarus_data_reco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "icarus_data_reco1_job = Job(icarus_data_reco1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 'ICARUS Data Stage0':\n",
      "N_Events: 50\n",
      "Memory (MB): 4000.000000\n",
      "Time (hr): 1.666667\n",
      "Event pass fraction: 1.000000\n",
      "Input/Output size (GB): 8.500000 / 2.500000\n",
      "Failure rate: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(icarus_data_reco1_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "icarus_data_reco_job = Job([icarus_data_reco1,icarus_data_reco2],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: '':\n",
      "N_Events: 50\n",
      "Memory (MB): 4000.000000\n",
      "Time (hr): 3.055556\n",
      "Event pass fraction: 1.000000\n",
      "Input/Output size (GB): 8.500000 / 2.250000\n",
      "Failure rate: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(icarus_data_reco_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "icarus_data_reco1_notrig = copy.copy(icarus_data_reco1)\n",
    "icarus_data_reco1_notrig.set_pass_fraction(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 'ICARUS Data Stage0':\n",
      "\tMemory (MB): 4000.000000\n",
      "\tTime per event (s): 120.000000\n",
      "\tInput/Output size per event (MB): 170.000000 / 50.000000\n",
      "\tThreads used (min,max): (1,1)\n",
      "\tEvent pass fraction: 1.000000\n",
      "\tFailure rate: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(icarus_data_reco1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 'ICARUS Data Stage0':\n",
      "\tMemory (MB): 4000.000000\n",
      "\tTime per event (s): 120.000000\n",
      "\tInput/Output size per event (MB): 170.000000 / 50.000000\n",
      "\tThreads used (min,max): (1,1)\n",
      "\tEvent pass fraction: 0.050000\n",
      "\tFailure rate: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(icarus_data_reco1_notrig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "icarus_data_reco_notrig = ChainProcesses([icarus_data_reco1_notrig,icarus_data_reco2],\"ICARUS Data Reco NoTrig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 'ICARUS Data Reco NoTrig':\n",
      "\tMemory (MB): 4000.000000\n",
      "\tTime per event (s): 125.000000\n",
      "\tInput/Output size per event (MB): 170.000000 / 2.250000\n",
      "\tThreads used (min,max): (1,1)\n",
      "\tEvent pass fraction: 0.050000\n",
      "\tFailure rate: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(icarus_data_reco_notrig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "icarus_data_pmtFilter = Process(name=\"ICARUS Data PMTFilter\",\n",
    "                                memory_MB=2000,\n",
    "                                time_s=2,\n",
    "                                input_MB=170,\n",
    "                                output_MB=50*0.05,\n",
    "                                pass_fraction=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "icarus_data_reco_notrig = ChainProcesses([icarus_data_pmtFilter,icarus_data_reco1,icarus_data_reco2],\"ICARUS Data Reco NoTrig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 'ICARUS Data Reco NoTrig':\n",
      "\tMemory (MB): 4000.000000\n",
      "\tTime per event (s): 13.000000\n",
      "\tInput/Output size per event (MB): 170.000000 / 2.250000\n",
      "\tThreads used (min,max): (1,1)\n",
      "\tEvent pass fraction: 0.050000\n",
      "\tFailure rate: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(icarus_data_reco_notrig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "icarus_data_reco_job_pmtfilter = Job([icarus_data_pmtFilter,icarus_data_reco1,icarus_data_reco2],n_events=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "tape_io_interface = DataIOInterface(name=\"FNAL Enstore\",rate_MBps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "icarus_data_reco_job_pmtfilter = Job(process=[icarus_data_pmtFilter,icarus_data_reco1,icarus_data_reco2],\n",
    "                                     n_events=50,\n",
    "                                     input_interface=tape_io_interface,\n",
    "                                     output_interface=tape_io_interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcache_io_interface = DataIOInterface(name=\"FNAL dCache\",rate_MBps=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "icarus_data_reco_job_pmtfilter_dcache = Job(process=[icarus_data_pmtFilter,icarus_data_reco1,icarus_data_reco2],\n",
    "                                     n_events=50,\n",
    "                                     input_interface=dcache_io_interface,\n",
    "                                     output_interface=dcache_io_interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: '':\n",
      "N_Events: 50\n",
      "Memory (MB): 4000.000000\n",
      "Time (hr): 0.185281\n",
      "\tCPU Time (hr): 0.180556\n",
      "\tIO Time (hr): 0.004725\n",
      "Event pass fraction: 0.050000\n",
      "Input/Output size (GB): 8.500000 / 0.005625\n",
      "Failure rate: 0.000000\n",
      "Process: '':\n",
      "N_Events: 50\n",
      "Memory (MB): 4000.000000\n",
      "Time (hr): 0.181343\n",
      "\tCPU Time (hr): 0.180556\n",
      "\tIO Time (hr): 0.000788\n",
      "Event pass fraction: 0.050000\n",
      "Input/Output size (GB): 8.500000 / 0.005625\n",
      "Failure rate: 0.000000\n"
     ]
    }
   ],
   "source": [
    "print(icarus_data_reco_job_pmtfilter)\n",
    "print(icarus_data_reco_job_pmtfilter_dcache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1./np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested n_events= 10000000.0  with n_jobs= None\n",
      "Setting n_events=10000000 with n_jobs=200000\n",
      "39.351852 0.520833\n",
      "Time to input data exceeds desired completion time: 39.351852 > 1.000000\n",
      "Input rate needed is 19675.925926 MBps (vs. specified 500.000000 MBps)\n",
      "Increasing completion time to 39.351852\n"
     ]
    }
   ],
   "source": [
    "sample_icarus_data_reco_pmtfilter = Sample(job=icarus_data_reco_job_pmtfilter,n_events=10e6,time_complete_days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample '':\n",
      "N_Events: 10000000\n",
      "N_Jobs: 200000\n",
      "N_Events_per_job: 50\n",
      "Input Datset Size (TB): 1700.000000\n",
      "Output Datset Size (TB): 22.500000\n",
      "Completion Time (days): 39.351852\n",
      "\tCPU Time (hr): 36111.111111\n",
      "\tWeighted CPU Time (hr): 72222.222222\n",
      "Peak slots: 76\n",
      "Bound: INPUT\n"
     ]
    }
   ],
   "source": [
    "print(sample_icarus_data_reco_pmtfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5e5*170/1000./1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested n_events= 10000000.0  with n_jobs= None\n",
      "Setting n_events=10000000 with n_jobs=200000\n",
      "6.558642 0.086806\n",
      "Time to input data exceeds desired completion time: 6.558642 > 1.000000\n",
      "Input rate needed is 19675.925926 MBps (vs. specified 3000.000000 MBps)\n",
      "Increasing completion time to 6.558642\n"
     ]
    }
   ],
   "source": [
    "sample_icarus_data_reco_pmtfilter_dcache = Sample(job=icarus_data_reco_job_pmtfilter_dcache,n_events=10e6,time_complete_days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample '':\n",
      "N_Events: 10000000\n",
      "N_Jobs: 200000\n",
      "N_Events_per_job: 50\n",
      "Input Datset Size (TB): 1700.000000\n",
      "Output Datset Size (TB): 22.500000\n",
      "Completion Time (days): 6.558642\n",
      "\tCPU Time (hr): 36111.111111\n",
      "\tWeighted CPU Time (hr): 72222.222222\n",
      "Peak slots: 458\n",
      "Bound: INPUT\n"
     ]
    }
   ],
   "source": [
    "print(sample_icarus_data_reco_pmtfilter_dcache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested n_events= 10000000.0  with n_jobs= None\n",
      "Setting n_events=10000000 with n_jobs=200000\n",
      "6.558642 0.086806\n",
      "10.030864 6.558642 0.086806\n"
     ]
    }
   ],
   "source": [
    "sample_icarus_data_reco_pmtfilter_dcache = Sample(job=icarus_data_reco_job_pmtfilter_dcache,n_events=10e6,max_slots=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample '':\n",
      "N_Events: 10000000\n",
      "N_Jobs: 200000\n",
      "N_Events_per_job: 50\n",
      "Input Datset Size (TB): 1700.000000\n",
      "Output Datset Size (TB): 22.500000\n",
      "Completion Time (days): 10.030864\n",
      "\tCPU Time (hr): 36111.111111\n",
      "\tWeighted CPU Time (hr): 72222.222222\n",
      "Peak slots: 300\n",
      "Bound: COMPUTE\n"
     ]
    }
   ],
   "source": [
    "print(sample_icarus_data_reco_pmtfilter_dcache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
